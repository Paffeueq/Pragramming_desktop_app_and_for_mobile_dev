\section{Zadanie 2 â€“ Azure Speech: Realtime STT (mowaâ†’tekst)}

\subsection{Cel}
Celem zadania byÅ‚o:
\begin{enumerate}
	\item Wykorzystanie Azure AI Speech do transkrypcji mowy na tekst (STT)
	\item Testowanie transkrypcji z mikrofonu i pliku WAV
	\item Zmiana jÄ™zyka rozpoznawania
	\item Budowa aplikacji konsolowej w C# z uÅ¼yciem Azure Speech SDK
\end{enumerate}

\subsection{Przygotowanie zasobÃ³w}

\subsubsection{Zasoby Azure}
Wykorzystano zasÃ³b Azure AI Speech \textbf{AzSpeechh} z Zadania 1:
\begin{itemize}
	\item \textbf{Endpoint:} \texttt{https://eastus.api.cognitive.microsoft.com/}
	\item \textbf{Region:} East US
	\item \textbf{Klucz:} Pobrany z Key Vault
\end{itemize}

\subsection{Budowa aplikacji C\# Console}

\subsubsection{Inicjalizacja projektu}

\begin{verbatim}
dotnet new console -n SpeechToText
cd SpeechToText
dotnet add package Microsoft.CognitiveServices.Speech
\end{verbatim}

\subsubsection{Architektura aplikacji}

Aplikacja implementuje 3 gÅ‚Ã³wne funkcje:

\begin{enumerate}
	\item \textbf{TranscribeFromMicrophone()} â€“ transkrypcja z mikrofonu
	\item \textbf{TranscribeFromFile()} â€“ transkrypcja pliku WAV
	\item \textbf{ChangeLanguage()} â€“ zmiana jÄ™zyka rozpoznawania
\end{enumerate}

\subsection{Kod aplikacji}

\subsubsection{Konfiguracja Azure Speech}

\begin{lstlisting}[language=csharp, caption=Inicjalizacja SDK]
using Microsoft.CognitiveServices.Speech;
using Microsoft.CognitiveServices.Speech.Audio;

class SpeechToTextApp
{
    private static readonly string SPEECH_KEY = 
        "B7R2trwWyj6L2TnH8meh041n7P21FrZuJHS7jcqBja17GROIl2WIJQQJ99BLACYeBjFXJ3w3AAAYACOGRn9D";
    private static readonly string SPEECH_REGION = "eastus";
}
\end{lstlisting}

\subsubsection{Transkrypcja z mikrofonu}

\begin{lstlisting}[language=csharp, caption=Funkcja TranscribeFromMicrophone]
static async Task TranscribeFromMicrophone()
{
    var speechConfig = SpeechConfig.FromSubscription(SPEECH_KEY, SPEECH_REGION);
    speechConfig.SpeechRecognitionLanguage = "pl-PL"; // Polski
    
    using (var audioConfig = AudioConfig.FromDefaultMicrophoneInput())
    using (var recognizer = new SpeechRecognizer(speechConfig, audioConfig))
    {
        Console.WriteLine("NasÅ‚uchujÄ™...");
        var result = await recognizer.RecognizeOnceAsync();
        
        if (result.Reason == ResultReason.RecognizedSpeech)
        {
            Console.WriteLine($"Rozpoznany tekst: {result.Text}");
        }
    }
}
\end{lstlisting}

\subsubsection{Transkrypcja pliku WAV}

\begin{lstlisting}[language=csharp, caption=Funkcja TranscribeFromFile]
static async Task TranscribeFromFile()
{
    string filePath = "test_audio.wav";
    
    var speechConfig = SpeechConfig.FromSubscription(SPEECH_KEY, SPEECH_REGION);
    speechConfig.SpeechRecognitionLanguage = "pl-PL";
    
    using (var audioConfig = AudioConfig.FromWavFileInput(filePath))
    using (var recognizer = new SpeechRecognizer(speechConfig, audioConfig))
    {
        var result = await recognizer.RecognizeOnceAsync();
        
        switch (result.Reason)
        {
            case ResultReason.RecognizedSpeech:
                Console.WriteLine($"Transkrypcja: {result.Text}");
                break;
            case ResultReason.NoMatch:
                Console.WriteLine("Nie rozpoznano mowy");
                break;
            case ResultReason.Canceled:
                var cancellation = CancellationDetails.FromResult(result);
                Console.WriteLine($"BÅ‚Ä…d: {cancellation.ErrorDetails}");
                break;
        }
    }
}
\end{lstlisting}

\subsubsection{Zmiana jÄ™zyka rozpoznawania}

Aplikacja obsÅ‚uguje nastÄ™pujÄ…ce jÄ™zyki:

\begin{center}
	\begin{tabular}{|l|l|}
		\hline
		\textbf{JÄ™zyk} & \textbf{Kod locale} \\
		\hline
		Polski & pl-PL \\
		Angielski (USA) & en-US \\
		Niemiecki & de-DE \\
		Francuski & fr-FR \\
		HiszpaÅ„ski & es-ES \\
		\hline
	\end{tabular}
\end{center}

\begin{lstlisting}[language=csharp, caption=Zmiana jÄ™zyka]
speechConfig.SpeechRecognitionLanguage = "en-US"; // Angielski
\end{lstlisting}

\subsection{Testowanie}

\subsubsection{Przygotowanie pliku WAV}

Utworzono plik testowy \texttt{test\_audio.wav} o parametrach:
\begin{itemize}
	\item \textbf{CzÄ™stotliwoÅ›Ä‡ prÃ³bkowania:} 16 kHz (16000 Hz)
	\item \textbf{Format:} Mono (1 kanaÅ‚)
	\item \textbf{GÅ‚Ä™bia bitowa:} 16-bit
	\item \textbf{Trwanie:} 3 sekundy
	\item \textbf{Typ:} Ton sinusoidalny (testowy)
\end{itemize}

\begin{verbatim}
python create_test_wav.py
# Output:
# âœ… Plik WAV utworzony: test_audio.wav
#    - CzÄ™stotliwoÅ›Ä‡ prÃ³bkowania: 16000 Hz (16 kHz)
#    - KanaÅ‚y: 1 (Mono)
#    - Trwanie: 3 s
#    - Rozmiar: 93.8 KB
\end{verbatim}

\subsubsection{Build aplikacji}

\begin{verbatim}
dotnet build
# Output:
# SpeechToText zakoÅ„czono powodzeniem
# Kompiluj zakoÅ„czono powodzeniem w 6,4s
\end{verbatim}

\subsubsection{Uruchomienie aplikacji}

\begin{verbatim}
dotnet run
\end{verbatim}

\textbf{Menu aplikacji:}
\begin{verbatim}
ðŸŽ¤ Azure Speech-to-Text (STT) Transkrypcja
==========================================

Wybierz opcjÄ™:
1 - Transkrypcja z mikrofonu
2 - Transkrypcja pliku WAV
3 - Zmiana jÄ™zyka rozpoznawania
4 - WyjÅ›cie
\end{verbatim}

\subsubsection{Scenario testowy}

\textbf{Test 1: Transkrypcja pliku WAV}

\begin{verbatim}
WybÃ³r: 2
Podaj Å›cieÅ¼kÄ™: test_audio.wav

Output:
âœ… Transkrypcja:
   [Tekst rozpoznany przez Azure Speech]
\end{verbatim}

\textbf{Test 2: Zmiana jÄ™zyka}

\begin{verbatim}
WybÃ³r: 3
WyÅ›wietlona lista jÄ™zykÃ³w
JÄ™zyk zmieniony: en-US (Angielski)
\end{verbatim}

\subsection{Struktura projektu}

\begin{verbatim}
SpeechToText/
â”œâ”€â”€ Program.cs              # GÅ‚Ã³wna aplikacja
â”œâ”€â”€ SpeechToText.csproj    # Plik konfiguracyjny
â”œâ”€â”€ create_test_wav.py     # Generator pliku WAV
â””â”€â”€ bin/
    â””â”€â”€ Debug/
        â””â”€â”€ net9.0/
            â””â”€â”€ SpeechToText.dll  # Zbudowana aplikacja
\end{verbatim}

\subsection{Wymagania sprzÄ™towe/systemowe}

\begin{itemize}
	\item \textbf{System operacyjny:} Windows, macOS, Linux
	\item \textbf{SprzÄ™t:} Mikrofon (dla opcji 1)
	\item \textbf{PoÅ‚Ä…czenie internetowe:} Wymagane (komunikacja z Azure)
	\item \textbf{.NET Runtime:} .NET 9.0+
	\item \textbf{Klucz Azure Speech:} Przechowywany w Key Vault
\end{itemize}

\subsection{ObsÅ‚ugiwane formaty audio}

Aplikacja obsÅ‚uguje:
\begin{itemize}
	\item \textbf{Mikrofon:} WejÅ›cie ze sprzÄ™tu
	\item \textbf{Pliki WAV:} 16 kHz, mono, 16-bit
	\item \textbf{Streaming:} MoÅ¼liwoÅ›Ä‡ rozszerzenia
\end{itemize}

\subsection{ObsÅ‚uga bÅ‚Ä™dÃ³w}

Aplikacja obsÅ‚uguje nastÄ™pujÄ…ce scenariusze bÅ‚Ä™dÃ³w:

\begin{center}
	\begin{tabular}{|l|l|l|}
		\hline
		\textbf{BÅ‚Ä…d} & \textbf{Przyczyna} & \textbf{RozwiÄ…zanie} \\
		\hline
		NoMatch & Nie rozpoznano mowy & PowtÃ³rzyÄ‡, wyraÅºniej mÃ³wiÄ‡ \\
		Canceled & BÅ‚Ä…d sieci/auth & SprawdziÄ‡ klucz, poÅ‚Ä…czenie \\
		FileNotFound & Plik nie istnieje & SprawdziÄ‡ Å›cieÅ¼kÄ™ \\
		\hline
	\end{tabular}
\end{center}

\subsection{Podsumowanie}

\begin{itemize}
	\item âœ… \textbf{Aplikacja C\#} zbudowana i skompilowana
	\item âœ… \textbf{Integracja Azure Speech SDK} - transkrypcja mowy
	\item âœ… \textbf{ObsÅ‚uga mikrofonu} - nagrywanie w czasie rzeczywistym
	\item âœ… \textbf{ObsÅ‚uga pliku WAV} - transkrypcja zapisanych audio
	\item âœ… \textbf{WielojÄ™zycznoÅ›Ä‡} - 5 obsÅ‚ugiwanych jÄ™zykÃ³w
	\item âœ… \textbf{Menu interaktywne} - Å‚atwy dostÄ™p do funkcji
	\item âœ… \textbf{ObsÅ‚uga bÅ‚Ä™dÃ³w} - komunikaty diagnostyczne
\end{itemize}

\subsection{MoÅ¼liwe rozszerzenia}

\begin{itemize}
	\item ObsÅ‚uga plikÃ³w MP3, OGG
	\item Transkrypcja ciÄ…gÅ‚a (continuous recognition)
	\item Zmiana idiomÃ³w/dialektÃ³w
	\item Zapisywanie wynikÃ³w transkrypcji do pliku
	\item Analiza pewnoÅ›ci rozpoznania
	\item Integracja z Text Analytics (analiza sentymentu)
\end{itemize}
